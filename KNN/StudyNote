k-近邻分类算法
------------------------------
利用数据的属性判断该条数据更靠近哪类。

优点： 精度高，对异常值不敏感，无数据输入假定。
缺点： 计算复杂度高、空间复杂度高

使用数据范围： 数值型喝标称型
        标称型：标称型目标变量的结果只在有限目标集中取值，如真与假(标称型目标变量主要用于分类)
        数值型：数值型目标变量则可以从无限的数值集合中取值，如0.100，42.001等 (数值型目标变量主要用于回归分析)
 

最近入坑了机器学习，为了快速提高自己的机器学习的代码能力，入坑了《机器学习实战》，
目前只学习了第一个重要算法:k近邻算法（kNN），在学习过程中发现许多相关的学习资料要么代码是python2的，要么代码的解释不够详细，
对于像我这样的菜鸡而言苦不堪言，为了后来者不踩我踩过的大坑，现在將这一章的学习笔记做一个小结，全文有些长，请根据自己的需要查看。


一.什么是kNN

首先上一段李航《统计学习方法》里kNN的算法总结

用人话来说就是，对于某一个群体里的某个个体，其某一特性取决于其周围最近的k个人的该特性的多数值。

这个就是k近邻算法的基本原理，下面结合机器学习实战，將这一算法进行实践。

注：编程语言：python3.7


二.kNN算法实践

任务目标：自己创建一个基本数据集，并建立一个基本分类器，基于创建的基本数据集对某一数据进行分类

任务实施：

1.创建数据集

利用createDateSet()函数建立一个数据集

并利用classify0()函数实现数据的分类

在这个数据集里，group代表了其具体坐标位置，labels代表了其标签（属性）

下面基于该数据集建立了一个基本分类器，该分类器將通过坐标，对其可能的属性是‘A’还是‘B’进行预测。下面是分类器部分的代码：

注意：书里为python2.7的代码，所以倒数第三行书里用的是iteritems()，但在python3里已经被item()代替

下面在terminal里运行这个分类器：

这里首先载入python,载入数据集后对[0,0]和[3,3]通过分类器分别判断其标签是‘A’还是‘B’


三.使用k-近邻算法选择约会对象

任务目标：通过每年飞行里程数，玩视频游戏所耗时间，冰淇淋消耗数来确定约会对象是否是意中人

任务实施：

因为我们的数据是以文本形式存储的，所以需要將文本转换为numpy矩阵，以便于將其带入现有函数来分类。

现在这一文本文件已经转换为了所需要的数组形式，现在这个问题就已经转换为之前的分类问题了，但是在分类前还需要对其进行归一化处理

现在，我们再將现有数据带入具体问题，以分类器的形式来实现这个问题，并集成为一个函数

不难发现，其错误率只有5%，所以算法效果不错，故我们以此算法为基础，来实现对于约会对象满意度的预测模型

此时，我将k改为4，错率率降到4%，knn分类器有了更好的表现


四.手写识别算法

任务目标：通过训练模型，希望模型能准确识别0-9的数字图像

任务实施：

首先要对图像进行预处理，前面我们获取的均是向量，虽然图像本质上也是种向量，但这种向量并不是我们之前分类器所使用的向量

为了方便处理，这里我们將图像均依次转化为一维向量，函数为img2vector(filename)

下面就是带入一个分类器，来实现手写图像识别，在这里使用两种方法

第一种：学习初期学习的knn分类器

发现分类结果错误11个，错误率为1.162791%

第二种：调用listdir方法和skelearn库

发现分类结果错误10个，错误率为1.057082%

两种方法结果都令人满意，所以我们可以认为这个算法满足我们的需要。
